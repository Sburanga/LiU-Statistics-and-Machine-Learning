## MSc Statistics and Machine Learning - *Linköping University*

In this file you can find the lab reports and lab content of the following courses:  
* [Machine Learning](#user-content-732a99---machine-learning--2018fall) / 2018Fall
* [Bioinformatics](#user-content-732a51---bioinformatics--2018fall) / 2018Fall
* [Visualization](#user-content-732a98---visualization--2018fall) / 2018Fall
* [Advanced R Programming](#user-content-732a94---advanced-r-programming--2018fall) / 2018Fall  
* [Computational Statistics](#user-content-732a90---computational-statistics--2019spring) / 2019Spring  
* [Neural Networks and Learning Systems](#user-content-732a55---neural-networks-and-learning-systems--2019spring) / 2019Spring  
* [Advanced Data Mining](#user-content-732a75---advanced-data-mining--2019spring) / 2019Spring  
* [Introduction to Python](#user-content-732a74---introduction-to-python--2019spring) / 2019Spring  
* [Bayesian Learning](#user-content-732a91---bayesian-learning--2019spring) / 2019Spring  
* [Big Data Analytics](#user-content-732a54---big-data-analytics--2019spring) / 2019Spring  
* [Sport Analytics](#user-content-phdcourse---sports-analytics--2019spring) / 2019Spring
* [Advanced Machine Learning](#user-content-732a96---advanced-machine-learning--2019fall) / 2019Fall  
* [Text Mining](#user-content-732a92---text-mining--2019fall) / 2019Fall  
* [Decision Theory](#user-content-732a66---decision-theory--2019fall) / 2019Fall  


### [732A99](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Machine%20Learning) - Machine Learning / 2018Fall  
The course introduces the main concepts and tools in machine learning which are necessary for professional work and research in data analytics. The course presents machine learning mainly from a probabilistic framework, but successful non-probabilistic methods are also covered. The labs of this course are written in R.  
This course covers:  
-- Basic concepts in machine learning. Software. Regression, regularization and model selection.  
-- Classification methods. Dimensionality reduction and uncertainty estimation.  
-- Kernel methods and support vector machines. Neural networks and deep learning.  
-- Ensemble methods and mixture models. Online Learning.  
-- Splines and additive models. High-dimensional problems.


* **[Block1 Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Machine%20Learning/Lab1)**: Logistic Regression; Confusion Matrix; K-Nearest Neighbor; K-fold Cross Validation; Linear Regression and Regularization; stepAIC / Akaike; Ridge Regression; LASSO Regression.

* **[Block1 Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Machine%20Learning/Lab2)**: Linear Discriminant Analysis (LDA); Decision Tree; Naive Bayes; ROC Curve; Non-Parametric Bootstrap; Parametric Bootstrap; Confidence&Prediction Bands; Principal Components Analysis (PCA); Independent Component Analysis (IDA).

* **[Block1 Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Machine%20Learning/Lab3)**: Kernel Methods (Forecast Example); Support Vector Machines; Neural Networks.

* **[Block2 Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Machine%20Learning/Lab1_Block2)**: Ensemble Methods; Mixture Models; EM Algorithm.

* **[Block2 Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Machine%20Learning/Lab2_Block2)**: Generalized Additive Models (GAM); Generalized Linear Model (GLM); High-Dimensional Methods; Nearest Shrunken Centroid; Elastic Net; Benjamini-Hochberg Method.

### [732A51](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bioinformatics) - Bioinformatics / 2018Fall  

The aim of the course was to first provide the students with the basic of biology needed to understand the statistical models applied in genetics and molecular biology. Afterwards, the course goes into details in:  
-- sequence analysis  
-- DNA modelling  
-- sequence alignments algorithms  
-- tree estimation methods  
-- phylogeny reconstruction  
-- quantitative trait modelling  
-- micro-array analysis  
-- functional genomics  
-- rough set-based classification  
The course provided the five following computer labs, done in R:

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bioinformatics/Lab1)**: Hardy–Weinberg equilibrium; genomic sequences (raw and FASTA format); use of BLAST
* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bioinformatics/Lab2)**: DNA sequence acquisition; DNA sequence simulation; sequence analysis; phylogeny reconstruction
* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bioinformatics/Lab3)**: trait modelling (geography-based); Brownian motions; Ornstein–Uhlenbeck processes
* **[Lab4](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bioinformatics/Lab4)**: research review; MA–plots; genetic cluster analysis; gene expressions
* **[Lab5](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bioinformatics/Lab5)**: use of the Rosetta package; reduction & discretization; rule-based network plots 

### [732A98](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Visualization) - Visualization / 2018Fall  
The aim of the course is to learn theoretical models and modern practical tools for data visualization and visual data analysis.  
This course covers:  
-- *gglot2*, *plotly*, *visNetwork* and *shiny* packages  
-- *static*, *interactive* and *dynamic* visualization and analysis.  
To see the reports you can click the links below and download html files, which are named as the report itself.

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Visualization/Lab1)**: Scatter plot, smoothing, histogram, shiny check-box application.

* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Visualization/Lab2)**: Perception in visualization, various scatter plots, 2d-density contour versus scatter plots, multidimensional scaling.

* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Visualization/Lab3)**: MapBox dot maps; choropleth maps; equidistant projection; conic equal area projection; violin plots; surface plot; choropleth map with a detailed rds map dataset.  
*N.B. No data uploaded (too big)*

* **[Lab4](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Visualization/Lab4)**: Heatmap; Ordered Heatmaps by using Euclidian distance and minus correlation, optimizing with Hamiltonian Path Length, Hierarchical Clustering and TSP algorithms; Parallel Coordinate Plots; Radar Chart; Trellis Plot; 3D Scatter Plot; Raster Type 2d-Density Plot; Interval Cut vs Shingles.

* **[Lab5](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Visualization/Lab5)**: Word Cloud; Phrase Networks; Word Trees; Interactive Scatter Plots; Interactive Bar Charts; Linked Scatter Plot; Interaction Operators.

* **[Lab6](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Visualization/Lab6)**: Network Visualization; Graphs; Animations of time series data; Animated Bubble Chart; Animated Bar Charts; 2D-tour Visualization.



### [732A94](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming) - Advanced R Programming / 2018Fall

This course covers subjects such as:  
-- Data structures  
-- Unit Testing  
-- Object Oriented Programming  
-- Complete R package Developing  
-- Code Performance  
-- HTTP requests and API usage  
-- Build a package with Travis CI


* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming/Lab1)**: Data structures in R.

* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming/Lab2)**: Loops, functions, general syntax of R.

* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming/Lab3)**: R package which contains euclidean distance and Dijkstra's algorithm functions.

* **[Lab4](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming/Lab4)**: R package which contains linear regression by using only basic R functions.

* **[Lab5](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming/Lab5)**: R package which uses a Web API. It uses HTTP requests to obtain the data. This Web API provides a worldwide air pollution and this application creates a local shiny app server and its client to visualize the pollution data for the cities that application supports.


<img src="https://raw.githubusercontent.com/Sburanga/LiU-Statistics-and-Machine-Learning/master/Advanced%20R%20Programming/Lab5/ss.png" width="471" height="338">

* **[Lab6](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming/Lab6)**: R package which contains different programming strategies which are: Brute Force; Dynamic Prog ramming; Greedy Heuristic; Parallelized Brute Force for knapsack problem.

### [732A90](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Computational%20Statistics) - Computational Statistics / 2019Spring

The course includes computational applications of statistics and covers as main topics:  
-- Computer arithmetics  
-- Optimization  
-- Random number generation  
-- Monte Carlo methods, MCMC  
-- Numerical model selection and hypothesis testing  
-- EM algorithm and stochastic optimization (specifically genetic algorithms).  
The programming language of the course is R and the course offers at least one application for each topic.

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Computational%20Statistics/Lab1)**: Some practices on different statistics and computer arithmetics in order to test and grasp floating points, arithmetics operations.

* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Computational%20Statistics/Lab2)**: optimizing a model parameter by Golden-Section Search algorithm and BFGS, also discussion of comparison of these methods on the plot.

* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Computational%20Statistics/Lab3)**: Cluster Sampling which provides sampling from a proportional set, each element does not have same probability to be drawn. And as another application of generating samples, inverse CDF and Acceptance/Rejection methods are used to generate from different distributions.

* **[Lab4](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Computational%20Statistics/Lab4)**: Implementation of Metropolis-Hasting and Gibbs sampling algorithms to generate samples.

* **[Lab5](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Computational%20Statistics/Lab5)**: Hypothesis testing, Jackknife, Confidence intervals by using bootstrap method.

* **[Lab6](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Computational%20Statistics/Lab6)**: Genetic Algorithm and EM algorithm implementations.



### [732A55](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Neural%20Networks%20and%20Learning%20Systems) - Neural Networks and Learning Systems / 2019Spring

The course aims to explain the differences between particular learning paradigms, selecting an appropriate method for solving a given problem and implementing the method.  

The course includes Supervised Learning, Unsupervised Learning and Reinforcement Learning. The methods were mostly implemented in Matlab, even though a lab dedicated to CNN was made in python.  
-- Supervised Learning: neural networks, linear discriminants, support vector machines, ensemble learning, boosting, deep learning.  
-- Unsupervised Learning: patterns in high-dimensional data, dimensionality reduction, clustering, principal component analysis, linear discriminant analysis.  
-- Reinforcement Learning: TD-learning, Q-learning

The course has written executions of almost all methods as well, together with their implementation.

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Neural%20Networks%20and%20Learning%20Systems/Lab1)** (MATLAB): Supervised Learning methods and implementation of KNN algorithm and Backpropagation algorithm. Evaluations of these algorithms on different datasets and discussion with supported by plots. Dataset4 is a hand-written digits data, so lab includes a digit recognition application with KNN algorithm and Neural Networks.

* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Neural%20Networks%20and%20Learning%20Systems/Lab2)** (MATLAB): Face recognition model with Haar-features and AdaBoost algorithm and its evaluations.

* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Neural%20Networks%20and%20Learning%20Systems/Lab3)** (Python, tensorflow): Application of an image recognition task on the dataset cifar10. This lab also includes some practices about kernels, manual convolution, convolution in tensorflow.

* **[Lab4](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Neural%20Networks%20and%20Learning%20Systems/Lab4)** (MATLAB): Reinforcement Learning with a maze solving problem in 4 different cases of maze generator. Detailed discussion on V-functions and decision of training hyperparameters such as discount-factor, learning-rate and exploration-factor.


### [732A75](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Data%20Mining) - Advanced Data Mining / 2019Spring

In this course all labs are done with Weka v3.6.12 and reports focus comparison of algorithms and choosing parameter. Additionally, Apriori, FP-grow algorithms; K-Means, K-medoids, PAM clustering, CLARA, CLARANS, BIRCH algorithms are studied and run step by step.

This course covers the following content:  
-- Clustering | Partitioning Methods: K-Means; K-Medoids; PAM; CLARA; CLARANS.  
-- Clustering | Hierarchical Methods: AGNES; DIANA; BIRCH; ROCK; CHAMELEON.  
-- Clustering | Density-Based Methods: DBSCAN; OPTICS; Denclue.  
-- Association Analysis: Apriori algorithm; FP-grow Algorithm; Monotone/Antimonotone Constraints

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Data%20Mining/Lab1)**: Clustering. K-Means, different k values and "good" cluster discussions.

* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Data%20Mining/Lab2)**: Association Analysis. Clustering a given dataset and using association analysis to describe the clusters.

* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Data%20Mining/Lab3)**: Association Analysis. Importance of the distance metric within the clustering algorithm.


### [732A74](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Introduction%20to%20Python) - Introduction to Python / 2019Spring

This course covers the following content:  
-- Python basics: programming environment and documentation, program flow, variables, comments, numerical operators, loops, conditional statements.  
-- Data structures: simple data types, tuples, lists, dictionaries, sets, iterators and generators.  
-- Functions and functional programming, anonymous lambda functions, comprehensions.  
-- Classes and object oriented programming, objects and message passing.  
-- The standard library, and touching upon essential third-party packages for graphics, scientific computing and data manipulation.  
-- Debugging.  
-- Creating Scripts.

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Introduction%20to%20Python/Lab1)**: Python Basics: data structures such as strings, dictionaries, and lists, write loops and comprehensions to iterate over sequential data such as lists of strings.

* **[Lab2a](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Introduction%20to%20Python/Lab2a)**: Python functions, procedural abstraction, some debugging or testing, and functional patterns. The focus is on using the basic language feature of functions (testing exceptions and assertions). 

* **[Lab2b](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Introduction%20to%20Python/Lab2b)**: More in-depth Python functions. Focus on recursion, Higher Order Functions (map, reduce, filter), declarative patterns, function states and parametrization. Tested with various sorting algorithms.

* **[Lab3a](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Introduction%20to%20Python/Lab3a)**: Python class and object concepts.

* **[Lab3b](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Introduction%20to%20Python/Lab3b)**: Python command-line script which generates text based on another text by using successors and their frequency.


### [732A91](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bayesian%20Learning) - Bayesian Learning / 2019Spring

The course aims to give a solid introduction to the Bayesian approach to statistical inference, with a view towards applications in data mining and machine learning. After an introduction to the subjective probability concept that underlies Bayesian inference, the course moves on to the mathematics of the prior-to-posterior updating in basic statistical models.  
The course has 4 modules:  
-- Bayesics: Basic concepts about likelihood, priors, (one|multi)-parameter models, marginalization.  
-- Bayesian Regression and Classification  
-- More advanced models, MCMC and Variational Bayes  
-- Model Inference and Variable Selection

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bayesian%20Learning/Lab1)**: Exploring posterior distributions in one-parameter models by simulation and direct numerical evaluation  
* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bayesian%20Learning/Lab2)**: Polynomial regression and classification with logistic regression  
* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Bayesian%20Learning/Lab3)**: MCMC using Gibbs sampling and Metropolis-Hastings  


### [732A54](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Big%20Data%20Analytics) - Big Data Analytics / 2019Spring

This course includes the following topics:  
-- Introduction to Big Data: concept and tools  
-- Parallel computing  
-- Databases for Big Data (NoSql, HDFS)  
-- Querying for Big Data (Spark, SparkSQL)  
-- Resource management in a cluster environment  
-- Parallelizing computations for Big Data. MapReduce concept.  
-- Machine Learning for Big Data  
The programming language of this course is Python; database technologies are Spark and SparkSQL. The structure of the big data which is used in labs can be found in the index of the repository. Please click the course code.  
*N.B. No data uploaded (too big)*

* **[Lab0](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Big%20Data%20Analytics/Lab0)**: Revision of relational databases (MySQL)  
* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Big%20Data%20Analytics/Lab1)**: Spark  
* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Big%20Data%20Analytics/Lab2)**: SparkSQL  
* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Big%20Data%20Analytics/Lab3)**: Machine learning application on Spark (Forecast Prediction with Kernel Methods)


### [PhDcourse](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Sports%20Analytics/Project) - Sports Analytics / 2019Spring

This course was part of different PhD programs of Linköping University and was open to my master as well. 
The course consisted of several lectures and seminars, with the focus on the final project, which counted as final exam as well.  

**Theoretical part**: several ML and statistical models applied to various sports and sport datasets. Football, basketball, baseball and hockey applications of spacial statistics and reinforcement learning were presented.

**Final project**: it consisted of an application developed with my classmate Martin Smelik for the local hockey team, Linköping Hockey Club (LHC). The cooperation was carried on outside the scope of the course as well. The team was in possession of the data of the shots received and made from more than 10 seasons, with the position of the ball at the moment of the shots (as well as many other variables).  

The app consists of:
* **Heatmaps** of the hockey rink
  * Displaying hot areas of the field
  * Giving the likelihood of receiving a shot from a specific area
  * Working for both attack and defense
* **Dynamic filters** for all the explanatory variables
  * Possibility of tuning multiple variables simultaneously and independently
  * Granting the possibility to investigate very specific situations
  * Allowing total freedom of choice from the user side
  * Applying the changes of the filters to the plot almost instantly
* **Continuous contact with the team staff**, in particular with the goalkeeper's coach Mikael Vernblom
A reduced version of the app (with simulated data) is available online at **[this link](https://steto820.shinyapps.io/Showcase_LHC_heatmap/)**.

### [732A96](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Machine%20Learning) - Advanced Machine Learning / 2019Fall

The aim of this course is to dig deeper into the statistical background of some key concepts of Machine Learning. In particular, it focuses on the probabilistic thinking of Bayesian Networks (BN), Hidden Markov Models (HMM), Reinforcement Learning and Gaussian Processes (GP). The lectures aim to comprehend each core mechanism of the models treated while the dedicated labs, done in R, force the student to both manually implement the formulas studied and use dedicated packages.  
The course has 4 modules:  
-- Graphical Models: Causal Models; Bayesian Networks
-- Hidden Markov Models: Markov Networks; Autoregressive HMM; Explicit-Duration HMM  
-- Reinforcement Learning: Linear Gaussian State Space Models; Bayes, Kalman & Particle Filter 
-- Gaussian Process Regression and Classification: Covariance Functions; GP Networks; Bayesian Optimization

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Machine%20Learning/Lab1)**: Exploring BN, their non-equivalent cases and partial independence of the variables on a lung-disease problem.
* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Machine%20Learning/Lab2)**: Creating an HMM to simulate the movement of a robot and then compute the most probable path according to different probability distributions.
* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Machine%20Learning/Lab3)**: Implementation of a particle filter for robot localization in different scenarios.
* **[Lab4](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Advanced%20Machine%20Learning/Lab4)**: Both implementation and use of built-in functions for GP regression and classification on different datasets.

### [732A92](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Text%20Mining) - Text Mining / 2019Fall

The course investigates several methods and techniques to extract data from documents and text and to analyze the information obtained. The following subjects were covered:
-- basic methods for information extraction and retrieval of textual data
-- text processing techniques to prepare documents for statistical modelling
-- relevant machine learning models for analyzing textual data and correctly interpretation of the results
-- machine learning models for text prediction
-- evaluation of performances of machine learning models for textual data

This course has 5 core contents with an assignment in each topic.

* **[Lab1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Text%20Mining/Lab1)**: Information Retrieval
  * Preprocessing with spacy
  * Tf-idf vectorizer from scikit-learn
  * Retrieval with K-NN algorithm
  * Keyword extraction
* **[Lab2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Text%20Mining/Lab2)**: Document Classification
  * Naive Bayes Classifier implementation with Pipeline module from scikit-learn
  * Balancing the dataset.
  * Creating Baseline and comparing different classifiers with Grid Search with Cross-Validation (GridSearchCV module)
* **[Lab3](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Text%20Mining/Lab3)**: Document Clustering
  * Clustering with K-means algorithm
  * Topic modelling with Latent Dirichlet Allocation
* **[Lab4](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Text%20Mining/Lab4)**: Natural Language Processing
  * Word embeddings
  * Analogies
  * Simple classifiers and a multi-layer perceptron classifier comparison.
* **[Lab5](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Text%20Mining/Lab5)**: Information Extraction
  * Named entity recognition and entity linking
  * Context-sensitive disambiguation
  
### [732A66](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Decision%20Theory) - Decision Theory / 2019Fall

The course started explaining the basic thinking of decision theory, beginning with empirical decision criteria and gradually building up to probabilistic models and decision making based on Bayesian criteria. The teaching sessions covered the following subjects:  
-- different interpretations of probability  
-- probabilistic reasoning and likelihood theory  
-- elements of Baysian inference  
-- elements of decision theory (actions, consequences, utility and loss)  
-- the value of information  
-- decisive inference and sampling from a decision-making perspective  
-- applications in forensic science  

This course did not have any computer lab, instead required to submit two written assignments covering the majority of the course topics.
* **[Assignment1](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Decision%20Theory/Assignment1)**: posterior probability, Bayesian distributions and fundamental of decision making
* **[Assignment2](https://github.com/Sburanga/LiU-Statistics-and-Machine-Learning/tree/master/Decision%20Theory/Assignment2)**: payoff tables, expected reward/utility criterion, value of information